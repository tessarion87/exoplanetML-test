{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7ab1079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import  classification_report\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import chime\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87a44e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model for classification\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "    def train(self, train_loader, criterion, optimizer, num_epochs):\n",
    "        for epoch in range(num_epochs):\n",
    "            for inputs, labels in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        with torch.no_grad():\n",
    "            outputs = self(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "        return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aef3c1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define neural network model for regression\n",
    "class Regression(nn.Module): \n",
    "# Note: because this is jupyter, may have to change size of first layer depending on input\n",
    "# and then reload the kernel\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "      nn.Linear(784, 64), \n",
    "      nn.ReLU(),\n",
    "      nn.Linear(64, 32),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(32, 1)\n",
    "    )\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    '''\n",
    "      Forward pass\n",
    "    '''\n",
    "    return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45317256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, train_loader):\n",
    "# training loop\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        # Set current loss value\n",
    "        current_loss = 0.0\n",
    "        # Iterate over the DataLoader for training data\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "          # Get and prepare inputs\n",
    "          inputs, targets = data\n",
    "          inputs, targets = inputs.float(), targets.float()\n",
    "          targets = targets.reshape((targets.shape[0],1))\n",
    "            # Zero the gradients\n",
    "          optimizer.zero_grad()\n",
    "          # Perform forward pass\n",
    "          outputs = model(inputs)\n",
    "          \n",
    "          # Compute loss\n",
    "          loss = loss_function(outputs, targets)\n",
    "      \n",
    "          # Perform backward pass\n",
    "          loss.backward()\n",
    "      \n",
    "          # Perform optimization\n",
    "          optimizer.step()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c98e9195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load atmospheric CRN metric data\n",
    "\n",
    "abiotic_flux=pd.read_csv('Archean Earth flux network metrics, no life.csv') # abiotic case\n",
    "biotic_flux=pd.read_csv('Archean Earth flux network metrics, with life.csv') # biotic case\n",
    "abiotic_steady_state=pd.read_csv('Archean Earth steady state network metrics, no life.csv') # weird abiotic case\n",
    "anomalous_high_flux=pd.read_csv('Archean Earth agnostic high flux network metrics, no life.csv') # second weird abiotic case\n",
    "\n",
    "exo_combined=pd.concat([abiotic_flux,biotic_flux,abiotic_steady_state,anomalous_high_flux])\n",
    "exo_data=exo_combined[['Mean degree','Average shortest path length','CH4 abundance']]\n",
    "exo_target=exo_combined['Has life?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4fadb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classifier input values\n",
    "input_size = exo_data.shape[1]\n",
    "hidden_size = 100\n",
    "num_classes=2 # because, hey, a planet either has life, or it doesn't!\n",
    "learning_rate = 0.01\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(exo_data,exo_target, test_size=0.2, random_state=23) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ae29ea6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data into PyTorch tensors, create datasets, and then tensors\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e59b9da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tessa/.local/lib/python3.10/site-packages/torch/autograd/graph.py:824: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "\n",
    "model = Classifier(input_size, hidden_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "model.train(train_loader, criterion, optimizer, num_epochs)\n",
    "chime.success()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0f03686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90      1093\n",
      "           1       0.78      0.86      0.82       531\n",
      "\n",
      "    accuracy                           0.88      1624\n",
      "   macro avg       0.85      0.87      0.86      1624\n",
      "weighted avg       0.88      0.88      0.88      1624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_pred = model.predict(X_test_tensor)\n",
    "y_pred_np = np.array(y_pred)\n",
    "\n",
    "correct = sum(y_test == y_pred_np)\n",
    "accuracy = correct / len(y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(classification_report(y_test, y_pred_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "730e2d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not too shabby!\n",
    "# Now let's try with spectral data\n",
    "\n",
    "exo_data=pd.read_csv('exo_data.csv')\n",
    "\n",
    "\n",
    "input_size = exo_data.shape[1]\n",
    "batch_size = 10\n",
    "model=Regression()\n",
    "n_epochs=100\n",
    "# loss function and optimizer\n",
    "loss_function =nn.MSELoss()\n",
    "  # mean square error\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "# input data\n",
    "exo_metrics=exo_data[['CH4 abundance','Mean degree','Average shortest path length','Clustering coefficient','Node betweenness centrality','Edge betweenness centrality']]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95221162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split and format data\n",
    "exo_target=exo_data['CFOS']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(exo_metrics,exo_target, test_size=0.2, random_state=23) \n",
    "\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor= torch.tensor(y_test.values,dtype=torch.float32)\n",
    "\n",
    "# load data\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "772842e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tessa/.local/lib/python3.10/site-packages/torch/autograd/graph.py:824: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "# train data\n",
    "model=training_loop(n_epochs,train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5712fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.06386992756949e+17\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "y_pred = model(X_test_tensor)\n",
    "model_score=r2_score(y_test_tensor.detach().numpy(),y_pred.detach().numpy())\n",
    "print(model_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0e25b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Huh. Looks like we're going to need to find a better metric for spectral information\n",
    "# Let's try spectral variance\n",
    "exo_target=exo_data['Spectral variance']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(exo_metrics,exo_target, test_size=0.2, random_state=23) \n",
    "\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor= torch.tensor(y_test.values,dtype=torch.float32)\n",
    "\n",
    "# load data\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c844ffbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=training_loop(n_epochs,train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6dc8f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(X_test_tensor)\n",
    "model_score=r2_score(y_test_tensor.detach().numpy(),y_pred.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c52f26c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hmmm...perhaps we should use the spectra as a whole, instead of trying to reduce each spectra down \n",
    "# to a single metric?\n",
    "\n",
    "# input data\n",
    "spectral_data=exo_data['Spectra'].to_list()\n",
    "exo_spectra=[]\n",
    "\n",
    "for l in range(len(spectral_data)): # data sanitation and conversion from str to list of list of floats\n",
    "    spectra_values=spectral_data[l].split(',')\n",
    "    for idx in range(len(spectra_values)):\n",
    "        spectra_values[idx]=spectra_values[idx].replace('[','')\n",
    "        spectra_values[idx]=spectra_values[idx].replace(']','')\n",
    "        spectra_values[idx]=float(spectra_values[idx])\n",
    "    exo_spectra.append(spectra_values)\n",
    "\n",
    "exo_spectra=np.array(exo_spectra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62d8e0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_49900/2089490514.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_tensor = torch.tensor(X_train_tensor,dtype=torch.float32)\n",
      "/tmp/ipykernel_49900/2089490514.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train_tensor = torch.tensor(y_train_tensor,dtype=torch.float32)\n",
      "/tmp/ipykernel_49900/2089490514.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test_tensor,dtype=torch.float32)\n",
      "/tmp/ipykernel_49900/2089490514.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test_tensor,dtype=torch.float32)\n",
      "/tmp/ipykernel_49900/2089490514.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_tensor = torch.tensor(X_train_tensor,dtype=torch.float32)\n",
      "/tmp/ipykernel_49900/2089490514.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train_tensor = torch.tensor(y_train_tensor,dtype=torch.float32)\n",
      "/tmp/ipykernel_49900/2089490514.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test_tensor,dtype=torch.float32)\n",
      "/tmp/ipykernel_49900/2089490514.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test_tensor,dtype=torch.float32)\n",
      "/tmp/ipykernel_49900/2089490514.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_tensor = torch.tensor(X_train_tensor,dtype=torch.float32)\n",
      "/tmp/ipykernel_49900/2089490514.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train_tensor = torch.tensor(y_train_tensor,dtype=torch.float32)\n",
      "/tmp/ipykernel_49900/2089490514.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test_tensor,dtype=torch.float32)\n",
      "/tmp/ipykernel_49900/2089490514.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test_tensor,dtype=torch.float32)\n",
      "/tmp/ipykernel_49900/2089490514.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_tensor = torch.tensor(X_train_tensor,dtype=torch.float32)\n",
      "/tmp/ipykernel_49900/2089490514.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train_tensor = torch.tensor(y_train_tensor,dtype=torch.float32)\n",
      "/tmp/ipykernel_49900/2089490514.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test_tensor,dtype=torch.float32)\n",
      "/tmp/ipykernel_49900/2089490514.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test_tensor,dtype=torch.float32)\n",
      "/tmp/ipykernel_49900/2089490514.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_tensor = torch.tensor(X_train_tensor,dtype=torch.float32)\n",
      "/tmp/ipykernel_49900/2089490514.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train_tensor = torch.tensor(y_train_tensor,dtype=torch.float32)\n",
      "/tmp/ipykernel_49900/2089490514.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test_tensor,dtype=torch.float32)\n",
      "/tmp/ipykernel_49900/2089490514.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test_tensor,dtype=torch.float32)\n",
      "/tmp/ipykernel_49900/2089490514.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_tensor = torch.tensor(X_train_tensor,dtype=torch.float32)\n",
      "/tmp/ipykernel_49900/2089490514.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train_tensor = torch.tensor(y_train_tensor,dtype=torch.float32)\n",
      "/tmp/ipykernel_49900/2089490514.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test_tensor,dtype=torch.float32)\n",
      "/tmp/ipykernel_49900/2089490514.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_tensor = torch.tensor(y_test_tensor,dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "#Going to flip things and try inferring topological metrics from spectra instead of the other way around\n",
    "\n",
    "metrics=['Mean degree','Average shortest path length','Clustering coefficient','Edge betweenness centrality','Node betweenness centrality','CH4 abundance']\n",
    "\n",
    "scores=[]\n",
    "for metric in metrics:\n",
    "#split and format data\n",
    "    exo_target=exo_metrics[metric]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(exo_spectra,exo_target, test_size=0.2, random_state=23) \n",
    "    X_train_tensor = torch.from_numpy(X_train)\n",
    "    X_train_tensor = torch.tensor(X_train_tensor,dtype=torch.float32)\n",
    "    y_train_tensor = torch.from_numpy(y_train.values)\n",
    "    y_train_tensor = torch.tensor(y_train_tensor,dtype=torch.float32)\n",
    "    X_test_tensor = torch.from_numpy(X_test)\n",
    "    X_test_tensor = torch.tensor(X_test_tensor,dtype=torch.float32)\n",
    "    y_test_tensor= torch.from_numpy(y_test.values)\n",
    "    y_test_tensor = torch.tensor(y_test_tensor,dtype=torch.float32)\n",
    "    # load data\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True) \n",
    "    # train data and assess accuracy\n",
    "    model=training_loop(n_epochs,train_loader)\n",
    "    y_pred = model(X_test_tensor)\n",
    "    model_score=r2_score(y_test_tensor.detach().numpy(),y_pred.detach().numpy())\n",
    "    scores.append(model_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f20f7004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 score for spectral data and Mean degree is 0.8537656664848328\n",
      "The R2 score for spectral data and Average shortest path length is 0.9189150929450989\n",
      "The R2 score for spectral data and Clustering coefficient is 0.8088566064834595\n",
      "The R2 score for spectral data and Edge betweenness centrality is 0.899590790271759\n",
      "The R2 score for spectral data and Node betweenness centrality is 0.8255785703659058\n",
      "The R2 score for spectral data and CH4 abundance is -0.012559056282043457\n"
     ]
    }
   ],
   "source": [
    "r2_scores=[]\n",
    "for metric,score in zip(metrics,scores):\n",
    "    print(\"The R2 score for spectral data and \"+metric+\" is \"+str(score))\n",
    "    r2_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4158cd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that's more like it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6c505b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
